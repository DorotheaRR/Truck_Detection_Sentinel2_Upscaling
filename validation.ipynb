{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Trucks Sentinel-2 - Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script for validating Sentinel-2 truck detection. It uses data from traffic count station, currently only in Germany. The validation is based on a recursive shortest path finder. However, in the future this should become much more efficient working only on the linestrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load creds\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# installations\n",
    "def install_package(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "install_package(\"obspy\")\n",
    "\n",
    "from xcube_sh.cube import open_cube\n",
    "from xcube_sh.config import CubeConfig\n",
    "\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "from pyproj import Proj, Transformer\n",
    "from obspy.geodetics import degrees2kilometers, kilometers2degrees\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 1 | Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VLD(): return \"validation\"\n",
    "def CSV_SEP(): return \";\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_main = os.getcwd()\n",
    "dir_not_commit = os.path.join(dir_main, \"not_commit\")\n",
    "dirs = {VLD():os.path.join(dir_main, VLD()), \"processing\":os.path.join(dir_main, \"processing\"), \n",
    "        \"truck_points\":os.path.join(dir_not_commit, \"processed\", \"overall\", \"acquisitions_trucks\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True count data related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 10\n",
    "minutes = 20\n",
    "def NAME_DATE(): return \"Datum\"\n",
    "def NAME_HOUR(): return \"Stunde\"\n",
    "def NAME_TR1(): return \"Lkw_R1\"\n",
    "def NAME_TR2(): return \"Lkw_R2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gadm = gpd.read_file(os.path.join(dirs[\"processing\"], \"processing_grid_gadm_eu27.geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"_2018.csv\"\n",
    "true_counts_paths = {os.path.join(dirs[VLD()], \"zst7781\"+suffix):(5599337, 400384),\n",
    "                     os.path.join(dirs[VLD()], \"zst7121\"+suffix):(5605914, 390060),\n",
    "                     os.path.join(dirs[VLD()], \"zst7955\"+suffix):(5589735, 374175),\n",
    "                     os.path.join(dirs[VLD()], \"zst7443\"+suffix):(5557659, 399612)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 2 | Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_id(point, grid_gadm):\n",
    "    point_in_box = []\n",
    "    for i, geom in enumerate(grid_gadm.geometry):\n",
    "        if geom.contains(point):\n",
    "            point_in_box.append(grid_gadm.bbox_id[i])\n",
    "    return point_in_box\n",
    "            \n",
    "def utm32N_to_4326(utm32n_point):\n",
    "    source_crs = \"EPSG:25832\"\n",
    "    target_crs = \"EPSG:4326\"\n",
    "    transformer = Transformer.from_crs(source_crs, target_crs)\n",
    "    transformed = transformer.transform(utm32n_point[1], utm32n_point[0])\n",
    "    return Point(transformed[1], transformed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 3 | Prep points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[789, 789, 789, 789]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_ids = []\n",
    "for path, point in true_counts_paths.items():\n",
    "    true_counts_paths[path] = utm32N_to_4326(point)\n",
    "    bbox_ids.append(get_bbox_id(true_counts_paths[path], grid_gadm)[0])\n",
    "bbox_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/Detect_Trucks_Sentinel2_Upscaling/not_commit/processed/overall/acquisitions_trucks/2018-05-08T10_40_25_acquisitions_trucks_bbox_id789.gpkg', '/home/jovyan/Detect_Trucks_Sentinel2_Upscaling/not_commit/processed/overall/acquisitions_trucks/2018-05-08T10_40_25_acquisitions_trucks_bbox_id789.gpkg', '/home/jovyan/Detect_Trucks_Sentinel2_Upscaling/not_commit/processed/overall/acquisitions_trucks/2018-05-08T10_40_25_acquisitions_trucks_bbox_id789.gpkg', '/home/jovyan/Detect_Trucks_Sentinel2_Upscaling/not_commit/processed/overall/acquisitions_trucks/2018-05-08T10_40_25_acquisitions_trucks_bbox_id789.gpkg']\n",
      "[1985, 1985, 1985, 1985]\n"
     ]
    }
   ],
   "source": [
    "def get_points(bbox_id):\n",
    "    files = glob(dirs[\"truck_points\"]+os.sep+\"2018*\"+str(bbox_id)+\".gpkg\")\n",
    "    n = []\n",
    "    if len(files) > 0:\n",
    "        for file in files:\n",
    "            points = gpd.read_file(file)\n",
    "            n.append(len(points))\n",
    "        n = np.array(n)\n",
    "        selected = n==n.max()\n",
    "        return np.array(files)[selected][0], n.max()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "truck_points_paths = []\n",
    "number = []\n",
    "for bbox_id in bbox_ids:\n",
    "    file, n = get_points(bbox_id)\n",
    "    truck_points_paths.append(file)\n",
    "    number.append(n)\n",
    "print(truck_points_paths)\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 4 | Utils for OSM rasterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osm geodataframe of polygons\n",
    "# reference_raster xarray with lat and lon\n",
    "def rasterize_osm(osm, reference_raster):\n",
    "    osm_values = list(set(osm[\"osm_value\"]))\n",
    "    nan_placeholder = 100\n",
    "    road_rasters = []\n",
    "    for osm_value in osm_values:\n",
    "        osm_subset = osm[osm[\"osm_value\"] == osm_value]\n",
    "        raster = rasterize(osm_subset, reference_raster.lat, reference_raster.lon)\n",
    "        cond = np.isfinite(raster)\n",
    "        raster_osm = np.where(cond, list(osm_subset.osm_value_int)[0], nan_placeholder) # use placeholder instead of nan first\n",
    "        raster_osm = raster_osm.astype(np.float)\n",
    "        road_rasters.append(raster_osm)        \n",
    "    # merge road types in one layer\n",
    "    road_raster_np = np.array(road_rasters).min(axis=0) # now use the lowest value (highest road level) because some intersect\n",
    "    road_raster_np[road_raster_np == nan_placeholder] = 0\n",
    "    return road_raster_np # 0=no_road 1=motorway, 2=trunk, ...\n",
    "\n",
    "def transform_lat_lon(lat, lon):\n",
    "    lat = np.asarray(lat)\n",
    "    lon = np.asarray(lon)\n",
    "    trans = Affine.translation(lon[0], lat[0])\n",
    "    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n",
    "    return trans * scale\n",
    "\n",
    "def rasterize(polygons, lat, lon, fill=np.nan):\n",
    "    transform = transform_lat_lon(lat, lon)\n",
    "    out_shape = (len(lat), len(lon))\n",
    "    raster = features.rasterize(polygons.geometry, out_shape=out_shape,\n",
    "                                fill=fill, transform=transform,\n",
    "                                dtype=float)\n",
    "    return xr.DataArray(raster, coords={\"lat\":lat, \"lon\":lon}, dims=(\"lat\", \"lon\"))\n",
    "\n",
    "def get_osm_raster(osm, grid_gadm, date, points_path):\n",
    "    bbox_id = int(os.path.basename(points_path).split(\"_\")[-1].split(\".\")[0][2:])\n",
    "    i = list(grid_gadm.bbox_id).index(bbox_id)\n",
    "    bbox = list(grid_gadm.geometry)[i].bounds\n",
    "    # get cube for rasterizing osm\n",
    "    config = CubeConfig(\n",
    "        dataset_name=\"S2L2A\",\n",
    "        band_names=[\"B04\"],\n",
    "        tile_size=[512, 512],\n",
    "        geometry=bbox,\n",
    "        spatial_res=0.00009,\n",
    "        time_range=[date, date])\n",
    "    cube = open_cube(config)\n",
    "    osm_np = rasterize_osm(osm, cube.B04)\n",
    "    return xr.Dataset({\"roadmask\":xr.DataArray(osm_np, coords={\"lat\":cube.lat, \"lon\":cube.lon}, dims=[\"lat\", \"lon\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 5 | Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator:\n",
    "    def __init__(self, truck_points_path, true_counts_path, station_xy):\n",
    "        self.eo_counts = gpd.read_file(truck_points_path) # gpd points\n",
    "        self.truck_points_path = truck_points_path\n",
    "        self.tc = TrueCounts(true_counts_path, station_xy)\n",
    "        self.osm_mask = None\n",
    "        self.bbox_id = int(os.path.basename(truck_points_path).split(\"_\")[-1].split(\".\")[0][2:])\n",
    "        self.eo_counts.crs = \"EPSG:4326\"\n",
    "        self.eo_counts_subset = None\n",
    "        self.truck_dist = None\n",
    "        self.within_dist = None\n",
    "        self.eo_vs_truth = None\n",
    "    \n",
    "    def subset_to_buffer(self, buffer):\n",
    "        self.eo_counts_subset = gpd.sjoin(self.eo_counts, buffer, op=\"within\")\n",
    "        \n",
    "    def within_distance(self, osm_mask, station, km_max_distance):\n",
    "        self.truck_dist = TruckDistance(osm_mask)\n",
    "        self.within_dist = 0\n",
    "        for point in self.eo_counts_subset.geometry:\n",
    "            self.truck_dist.calc_travel_dist(point, station)\n",
    "            dist = self.truck_dist.dist \n",
    "            if dist is not None and dist <= km_max_distance:\n",
    "                self.within_dist += 1\n",
    "                \n",
    "    def validate(self, date, hour, minutes, speed, grid_gadm, dir_not_commit):\n",
    "        self.tc.sub_hour_count(date[2:4]+date[5:7]+date[8:], hour, minutes)\n",
    "        self.tc.buffer(minutes, speed)\n",
    "        print(self.bbox_id)\n",
    "        osm = gpd.read_file(os.path.join(dir_not_commit, \"ancillary_data\", \"roads\", str(self.bbox_id)+\"_\"+\"highway.gpkg\"))\n",
    "        self.osm_mask = get_osm_raster(osm, grid_gadm, date, self.truck_points_path)\n",
    "        osm_in_buffer = gpd.overlay(self.tc.buff, osm)\n",
    "        # mask osm raster to buffered osm\n",
    "        bounds = osm_in_buffer.total_bounds\n",
    "        lat, lon = self.osm_mask.lat.values, self.osm_mask.lon.values\n",
    "        lat_bounds = (lat >= bounds[1]) * (lat <= bounds[3])\n",
    "        lon_bounds = (lon >= bounds[0]) * (lon <= bounds[2])\n",
    "        mesh = np.meshgrid(lon_bounds, lat_bounds)\n",
    "        mask = mesh[0]*mesh[1]\n",
    "        self.osm_mask = self.osm_mask.where(mask)\n",
    "        self.osm_mask.roadmask.values[np.isnan(self.osm_mask.roadmask.values)] = 0.\n",
    "        self.subset_to_buffer(self.tc.buff)\n",
    "        self.within_distance(self.osm_mask, self.tc.station_xy, self.tc.max_distance)\n",
    "        eo_count = self.within_dist / 2 # divide by two in order to include only lanes where trucks are coming from the station\n",
    "        self.eo_vs_truth = {\"date\":date, \"eo_count\":eo_count, \"true_count\":self.tc.counts, \"percentage\":(eo_count / self.tc.counts) * 100, \"cars\":self.tc.cars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueCounts:\n",
    "    def __init__(self, true_count_csv, station_xy):\n",
    "        self.data = pd.read_csv(true_count_csv, sep=CSV_SEP())\n",
    "        self.station_xy = station_xy\n",
    "        self.data_subset = None # pd\n",
    "        self.counts = None\n",
    "        self.cars = None\n",
    "        self.buff = None # gpd polygon\n",
    "        self.max_distance = None\n",
    "    \n",
    "    def sub_hour_count(self, date, hour, minutes):\n",
    "        self.minutes = minutes\n",
    "        self.data_subset = self.data[self.data[NAME_DATE()]==int(date)]\n",
    "        self.data_subset = self.data_subset[self.data_subset[NAME_HOUR()]==hour]\n",
    "        amount = minutes / 60\n",
    "        tr1, tr2 = NAME_TR1(), NAME_TR2()\n",
    "        self.counts = float(self.data_subset[tr1]) * amount + float(self.data_subset[tr2]) * amount\n",
    "        self.cars = float(self.data_subset[\"Pkw_R1\"]) * amount + float(self.data_subset[\"Pkw_R2\"]) * amount\n",
    "    \n",
    "    def max_traveled_dist(self, minutes, speed):\n",
    "        self.max_distance = speed / (60 / minutes) # km\n",
    "        \n",
    "    def buffer(self, minutes, speed):\n",
    "        self.max_traveled_dist(minutes, speed)\n",
    "        self.buff = gpd.GeoDataFrame(geometry=[self.station_xy.buffer(kilometers2degrees(self.max_distance))])\n",
    "        self.buff.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathFinder:\n",
    "    def __init__(self, arr, end):\n",
    "        self.arr = arr # np\n",
    "        self.end = end\n",
    "        self.paths = []\n",
    "        self.reached = []\n",
    "        self.len = []\n",
    "        self.shortest_path = None\n",
    "\n",
    "    def find_path(self, start):\n",
    "        self.find(start) \n",
    "        length = np.array(self.len)\n",
    "        if any(self.reached):\n",
    "            shortest = length==length[self.reached].min()\n",
    "            target = np.multiply(np.array(shortest), np.array(self.reached))\n",
    "            path = self.paths[int(np.where(target)[0][0])]\n",
    "            self.shortest_path = [path[:,0], path[:,1]]\n",
    "    \n",
    "    def should_follow(self, y, x, point, arr):                            \n",
    "        y_altered = point[0] + y\n",
    "        x_altered = point[1] + x                                                    \n",
    "        exceeds_y = y_altered >= arr.shape[0]\n",
    "        exceeds_x = x_altered >= arr.shape[1]\n",
    "        below_y = y_altered < 0\n",
    "        below_x = x_altered < 0\n",
    "        outside = any([exceeds_y, exceeds_x, below_y, below_x])\n",
    "        follow = not outside and arr[y_altered,x_altered] > 0\n",
    "        return follow\n",
    "\n",
    "    def find(self, point):\n",
    "        arr = self.arr\n",
    "        if not (point[0] == self.end[0] and point[1] == self.end[1]):\n",
    "            shift = 2999\n",
    "            y_neighbors = [-shift,-shift,-shift,0,0,shift,shift,shift] \n",
    "            x_neighbors = [-shift,0,shift,-shift,shift,-shift,0,shift] \n",
    "            valid = []\n",
    "            # check if end point is in window\n",
    "            bounds = (point[0]+y_neighbors[0], point[1]+x_neighbors[0], point[0]+y_neighbors[-1], point[1]+x_neighbors[-1])\n",
    "            point_in_box = self.end[0] >= bounds[0] and self.end[0] <= bounds[2] and self.end[1] >= bounds[1] and self.end[1] <= bounds[3]\n",
    "            if point_in_box: \n",
    "                valid.append(self.end)\n",
    "            else:\n",
    "                for y in range(-shift, shift):\n",
    "                    if np.abs([y]) == shift: # edges\n",
    "                        for x in range(-shift, shift):\n",
    "                            if self.should_follow(y, x, point, arr):\n",
    "                                valid.append(np.array([point[0]+y, point[1]+x]))\n",
    "                    else:\n",
    "                        for x in [-shift, shift]: # edges\n",
    "                            if self.should_follow(y, x, point, arr):\n",
    "                                valid.append(np.array([point[0]+y, point[1]+x]))\n",
    "            if len(valid) > 0:\n",
    "                if len(valid)>=2 and all(valid[0] == valid[1]):\n",
    "                    raise Exception(\"Nonono\")\n",
    "                origin_path = [np.array(point)] if len(self.paths) == 0 else self.paths[-1].copy()\n",
    "                for i, p in enumerate(valid):\n",
    "                    p = np.array(p)\n",
    "                    already_in = []\n",
    "                    for origin in origin_path:\n",
    "                        already_in.append(all(p==np.array(origin)))\n",
    "                    if not any(already_in):\n",
    "                        new_path = np.vstack([origin_path, p])\n",
    "                        self.paths.append(new_path)\n",
    "                        self.reached.append(all(new_path[new_path.shape[0]-1] == np.array(self.end)))\n",
    "                        self.len.append(len(new_path))\n",
    "                        self.find(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruckDistance:\n",
    "    def __init__(self, osm_mask):\n",
    "        self.osm_mask = osm_mask.roadmask\n",
    "        self.lon_lat = {\"lat\":osm_mask.lat.values, \"lon\":osm_mask.lon.values}\n",
    "        self.pf = None\n",
    "        self.line = None\n",
    "        self.dist = None\n",
    "        \n",
    "    # a shapely Point truck\n",
    "    # b shapely Point station\n",
    "    def calc_travel_dist(self, a, b):\n",
    "        indices_a = int(np.where(self.lon_lat[\"lat\"] == a.y)[0]), int(np.where(self.lon_lat[\"lon\"] == a.x)[0])\n",
    "        b_deviation_y, b_deviation_x = np.abs(self.lon_lat[\"lat\"]-b.y), np.abs(self.lon_lat[\"lon\"]-b.x)\n",
    "        indices_b = int(np.where(b_deviation_y == b_deviation_y.min())[0]), int(np.where(b_deviation_x == b_deviation_x.min())[0])\n",
    "        self.pf = PathFinder(self.osm_mask.values, indices_b)\n",
    "        self.pf.find_path(indices_a)\n",
    "        path = self.pf.shortest_path\n",
    "        if path is None:\n",
    "            self.dist = None\n",
    "        else:\n",
    "            self.indices_to_line(path)\n",
    "            self.dist = degrees2kilometers(self.line.length)    \n",
    "        \n",
    "    def indices_to_line(self, path):\n",
    "        lat = self.lon_lat[\"lat\"][path[0]]\n",
    "        lon = self.lon_lat[\"lon\"][path[1]]\n",
    "        df = pd.DataFrame({\"lat\":lat, \"lon\":lon})\n",
    "        points = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "        self.line = LineString([x for x in points.geometry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## 5 | Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating 0\n",
      "789\n",
      "Done with 0\n",
      "Validating 1\n",
      "789\n",
      "Done with 1\n",
      "Validating 2\n",
      "789\n",
      "Done with 2\n",
      "Validating 3\n",
      "789\n",
      "Done with 3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "eo_vs_truth = []\n",
    "n = len(truck_points_paths)\n",
    "for i in range(n):\n",
    "    print(\"Validating %s\" %(str(i)))\n",
    "    fpath_points = truck_points_paths[i]\n",
    "    if fpath_points is None:\n",
    "        eo_vs_truth.append(None)\n",
    "    else:\n",
    "        date = os.path.basename(truck_points_paths[i])[0:10]\n",
    "        true_counts_path = list(true_counts_paths.keys())[i]\n",
    "        station_xy = list(true_counts_paths.values())[i]\n",
    "        validator = Validator(\n",
    "            fpath_points, \n",
    "            true_counts_path, \n",
    "            station_xy\n",
    "        )\n",
    "        validator.validate(date, hour, minutes, speed, grid_gadm, dir_not_commit)\n",
    "        print(\"Done with %s\" %(str(i)))\n",
    "        eo_vs_truth.append(validator.eo_vs_truth)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2018-05-08',\n",
       "  'eo_count': 221.0,\n",
       "  'true_count': 253.33333333333331,\n",
       "  'percentage': 87.23684210526316,\n",
       "  'cars': 933.3333333333333},\n",
       " {'date': '2018-05-08',\n",
       "  'eo_count': 251.0,\n",
       "  'true_count': 291.3333333333333,\n",
       "  'percentage': 86.15560640732267,\n",
       "  'cars': 1020.6666666666666},\n",
       " {'date': '2018-05-08',\n",
       "  'eo_count': 249.5,\n",
       "  'true_count': 407.3333333333333,\n",
       "  'percentage': 61.252045826513914,\n",
       "  'cars': 793.6666666666666},\n",
       " {'date': '2018-05-08',\n",
       "  'eo_count': 192.0,\n",
       "  'true_count': 270.0,\n",
       "  'percentage': 71.11111111111111,\n",
       "  'cars': 547.3333333333333}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eo_vs_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(true_counts_paths.values())\n",
    "stations = gpd.GeoDataFrame({\"geometry\":points, \"station\":[7781, 7121, 7955,7443]})\n",
    "stations.to_file(os.path.join(dirs[VLD()], \"stations.geojson\"), driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
