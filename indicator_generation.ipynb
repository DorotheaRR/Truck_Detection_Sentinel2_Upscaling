{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truck Detection Indicator and COG calculation for ESA RACE Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For integrating analysis results into the Rapid Action on coronovirus and EO (RACE) Dashboard, some postprocessing steps are currently (July 2020) required:\n",
    "1. Indicator calculation in AOI and provision in specific format\n",
    "2. Point (GPKG) conversion to Cloud-Optimized-Geotiffs (COGs)\n",
    "\n",
    "This script does both of the steps. \n",
    "\n",
    "**[1]** The indicators are calculated in administrative areas from the Database of Global Administrative Areas. You can determine for which countries you would like to calculate the indicators as well as the years used. Currently, the threshold for denoting a deviation from the baseline as High or Low is +5 and -5 % respectively. You may also determine the roads for which calculate the indicator. By default, trunks and primary roads are combined as trunks are only are small percentage of roads and comparable to primary roads.\n",
    "\n",
    "**[2]** For the COG generation the points are aggregated in macropixels. Their observations-normalized counts are written to the macropixel covering a specific area. These rasters are written and converted to COGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, datetime\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.mask import mask\n",
    "from affine import Affine\n",
    "from shapely.geometry import box\n",
    "from glob import glob\n",
    "\n",
    "def install_package(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "install_package(\"geocube\")\n",
    "install_package(\"obspy\")\n",
    "from geocube.api.core import make_geocube\n",
    "from obspy.geodetics import kilometers2degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_fname = \"indicatorCode_HenrikFisser_20200721.csv\"\n",
    "years = [2017, 2018, 2019, 2020] # all included years\n",
    "deviation_threshold = 5 # % deviation to be denoted as High or Low (+5 or -5 % from reference)\n",
    "fully_covered_month = \"05\" # a month in the middle of the period\n",
    "road_types = [\"Motorway\", \"Trunk\", \"Primary\"]\n",
    "combine_primary_and_trunk = True # Trunk and Primary will be combined if True\n",
    "create_level1_indicators = [\"Germany\", \"France\", \"Spain\", \"Italy\", \"Austria\", \"United Kingdom\", \"Poland\", \n",
    "                            \"Greece\", \"Sweden\", \"Finland\"] # countries for which also indicators on GADM level 1 shall be calculated\n",
    "include = ['Åland','Andorra', 'Austria', 'Belgium', 'Bulgaria', 'Switzerland', 'Cyprus', \n",
    "           'Czech Republic', 'Germany', 'Denmark', 'Spain', 'Estonia', 'Finland', 'France', \n",
    "           'Faroe Islands', 'United Kingdom', \"Isle of Man\", 'Guernsey', 'Gibraltar', 'Greece', 'Croatia', \n",
    "           'Hungary', 'Ireland', 'Italy', 'Jersey', 'Liechtenstein', 'Lithuania', 'Luxembourg',\n",
    "           'Latvia', 'Monaco', 'Malta', 'Netherlands', 'Poland', 'Portugal', \n",
    "           'Romania', 'San Marino', 'Slovakia', 'Slovenia', 'Sweden'] # countries to be included in general, must be denoted as in GADM0 NAME_0\n",
    "color_codes = {\"High\":\"GREEN\", \"Normal\":\"BLUE\", \"Low\":\"RED\"}\n",
    "merged = \"trucks_points_merged\"\n",
    "indicator_template_name=\"N3_Master_20200703T10-23.csv\"\n",
    "ext = \".gpkg\"\n",
    "crs = \"EPSG:4326\"\n",
    "main_dir = os.getcwd()\n",
    "dir_not_commit = os.path.join(main_dir, \"not_commit\")\n",
    "dirs = {\"processing\":os.path.join(main_dir, \"processing\"), merged:os.path.join(dir_not_commit, \"processed\", \"overall\", merged),\n",
    "        \"indicators\":os.path.join(dir_not_commit, \"indicators\"), \"COG\":os.path.join(dir_not_commit, \"processed\", \"overall\", \"COG\")}\n",
    "def get_fname(year, merged): return merged + \"_\" + str(year)\n",
    "def get_fname_gadm(fname, ext): return fname + \"_\" + \"gadm\" + ext\n",
    "def get_country_code(points_gadm): \n",
    "    code = points_gadm.GID_0.unique()[0][0:2]\n",
    "    code = \"EE\" if points_gadm.NAME_0.unique()[0]==\"Estonia\" else code # otherwise duplicate with Spain ('ES')\n",
    "    return code\n",
    "d = dirs[\"processing\"]\n",
    "gadm0 = gpd.read_file(os.path.join(d, \"gadm36_0.shp\"))\n",
    "gadm1 = gpd.read_file(os.path.join(d, \"gadm36_1_subset.geojson\"))\n",
    "pop_places = gpd.read_file(os.path.join(d, \"ne_10m_populated_places_simple.shp\"))\n",
    "capitals = pop_places[pop_places[\"featurecla\"]==\"Admin-0 capital\"]\n",
    "gadm0.crs = crs\n",
    "gadm1.crs = crs\n",
    "capitals.crs = crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join points with GADM information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    fname = get_fname_gadm(get_fname(year, merged), \".gpkg\")\n",
    "    fpath = os.path.join(dirs[merged], fname)\n",
    "    if not os.path.exists(fpath):\n",
    "        points = gpd.read_file(os.path.join(dirs[merged], fname))\n",
    "        points.crs = crs\n",
    "        points_gadm0 = gpd.sjoin(points, gadm0, \"left\", \"within\")\n",
    "        points_gadm0 = points_gadm0.drop(\"index_right\", 1)\n",
    "        points_gadm0_gadm1 = gpd.sjoin(points_gadm0, gadm1, \"left\", \"within\")\n",
    "        points_gadm0_gadm1 = points_gadm0_gadm1.drop(\"index_right\", 1)\n",
    "        points_gadm0_gadm1.to_file(fpath, driver=\"GPKG\")\n",
    "print(\"Done with GADM join\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for indicator population and calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_indicator(indicators, i, subset, description, year, month, region, aoi, sub_aoi):\n",
    "    sum_mean_trucks = np.array(subset[\"truck_count_normalized\"]).flatten().sum()\n",
    "    indicators.at[i,\"AOI\"] = \"'\"+str(aoi)+\"'\"\n",
    "    indicators.at[i,\"Country\"] = \"'\"+get_country_code(subset)+\"'\"\n",
    "    indicators.at[i,\"Region\"] = \"'\"+region+\"'\" if region == \"None\" else \"'\"+region+\" Region'\"\n",
    "    indicators.at[i,\"City\"] = \"'None'\"\n",
    "    indicators.at[i,\"Site Name\"] = \"'None'\"\n",
    "    indicators.at[i,\"Description\"] = \"'\"+description+\"'\"\n",
    "    indicators.at[i,\"Method\"] = \"'Inter-band parallax moving object detection on roads'\"\n",
    "    indicators.at[i,\"EO Sensor\"] = \"'Sentinel 2'\"\n",
    "    indicators.at[i,\"Input Data\"] = \"'Sentinel 2 L2A'\"\n",
    "    indicators.at[i,\"Time\"] = \"'\"+str(year)+\"-\"+month+\"-\"+\"15'\" # YYYY-MM-DD\n",
    "    indicators.at[i,\"Measurement Value\"] = float(sum_mean_trucks)\n",
    "    indicators.at[i,\"Reference Description\"] = \"''\" # update according to used year(s)\n",
    "    indicators.at[i,\"Rule\"] = \"'(counts_2020/median_reference)*100-100 < -5% outputs LOW [reference = median of reference years]'\"\n",
    "    indicators.loc[i,\"Sub-AOI\"] = \"'\"+sub_aoi+\"'\"\n",
    "    indicators.at[i,\"Y axis\"] = \"'Trucks per observation'\"\n",
    "    #indicators.at[i,\"Indicator Name\"] = \"\"\n",
    "    indicators.at[i,\"Data Provider\"] = \"'Henrik Fisser, University of Würzburg, Germany'\"\n",
    "    #indicators.at[i,\"AOI_ID\"] = \"\"\n",
    "    indicators.at[i,\"Update frequency\"] = \"'Monthly'\"\n",
    "    return indicators\n",
    "    \n",
    "def get_road_subset(subset, road, combine_primary_and_trunk):\n",
    "    subset_road_type = subset[subset.osm_name==road]                      \n",
    "    if road == \"Primary\" and combine_primary_and_trunk:\n",
    "        subset_road_type = subset_road_type.append(subset[subset.osm_name==\"Trunk\"])\n",
    "    return subset_road_type\n",
    "\n",
    "def get_description(road):\n",
    "    road = road if road == \"Motorway\" or road == \"Trunk\" else \"Trunk/Primary\"\n",
    "    return \"Regional \" + road + \" truck traffic\"\n",
    "\n",
    "def get_indicator_value(indicators, index, ref, threshold):\n",
    "    m = indicators.at[index,\"Measurement Value\"]\n",
    "    dev = np.float(m / ref * 100 - 100)\n",
    "    if np.abs(dev) > threshold:\n",
    "        return \"Low\" if dev < 0 else \"High\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "def calc_indicators(indicators, indicator_road, deviation_threshold, color_codes):\n",
    "    time_values = list(indicator_road.Time)\n",
    "    reference_values = {}\n",
    "    indices = {}\n",
    "    ref_years = [\"2017\", \"2018\", \"2019\"]\n",
    "    for i, t in enumerate(time_values):\n",
    "        y = t[1:5]\n",
    "        indices[y] = indicator_road.index[i]\n",
    "        if y in ref_years: # reference\n",
    "            reference_values[y] = indicator_road.iloc[i][\"Measurement Value\"]\n",
    "    ref_vals = []\n",
    "    if \"2017\" in reference_values.keys(): ref_vals.append(reference_values[\"2017\"])\n",
    "    if \"2018\" in reference_values.keys(): ref_vals.append(reference_values[\"2018\"])\n",
    "    if \"2019\" in reference_values.keys(): ref_vals.append(reference_values[\"2019\"])\n",
    "    # Reference value\n",
    "    ref_vals_copy = ref_vals.copy()\n",
    "    ref_vals = np.array(ref_vals)\n",
    "    ref_vals.sort()\n",
    "    if len(ref_vals) > 2:\n",
    "        ref_vals = [ref_vals[1]] # take median value\n",
    "    ref_years = [list(reference_values.keys())[ref_vals_copy.index(val)] for val in ref_vals]\n",
    "    years = list(reference_values.keys())\n",
    "    y = \"2020\"\n",
    "    years.append(y)\n",
    "    for year in years:\n",
    "        index = indices[year]\n",
    "        if year in ref_years or year == \"2020\":\n",
    "            indicators.at[index,\"Reference value\"] = \"'\"+str(list(ref_vals))+\"'\"\n",
    "            indicators.at[index,\"Reference Description\"] = \"'Detected trucks in same period: \"+str(ref_years)+\"'\"\n",
    "            # Indicator Value\n",
    "            val = get_indicator_value(indicators, index, np.array(ref_vals).mean(), deviation_threshold)        \n",
    "            indicators.at[index,\"Indicator Value\"] = \"'\"+val+\"'\"\n",
    "            # Color code\n",
    "            indicators.at[index,\"Color code\"] = \"'\"+color_codes[val]+\"'\"\n",
    "    return indicators\n",
    "\n",
    "def get_indicator_code(road):\n",
    "    return \"E12c\" if road.lower() == \"motorway\" else \"E12d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "Regions\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "Done with indicator populating\n"
     ]
    }
   ],
   "source": [
    "indicators = pd.read_csv(os.path.join(dirs[\"indicators\"], indicator_template_name))\n",
    "for i in range(len(indicators)): indicators = indicators.drop(i)\n",
    "if \"Trunk\" in road_types and \"Primary\" in road_types and combine_primary_and_trunk:\n",
    "    road_types.remove(\"Trunk\")\n",
    "i = -1 # for populating rows\n",
    "print(\"Countries\")\n",
    "for year in years:\n",
    "    print(year)\n",
    "    fname_gadm = get_fname_gadm(get_fname(year, merged), ext)\n",
    "    points = gpd.read_file(os.path.join(dirs[merged], fname_gadm)) # read points with gadm information\n",
    "    points.crs = crs\n",
    "    points.rename(columns={\"NAME_1_right\":\"NAME_1\"}, inplace=True)\n",
    "    gadm0_unique, gadm1_unique = list(points.NAME_0.unique()), list(points.NAME_1.unique())\n",
    "    for country in gadm0_unique:\n",
    "        # calc indicator stats for countries\n",
    "        subset = points[points[\"NAME_0\"]==country]\n",
    "        region = \"None\"\n",
    "        sub_aoi = gadm0[gadm0.NAME_0 == country].geometry.iloc[0].wkt    \n",
    "        if len(subset) > 0:\n",
    "            # get capital point from pop places\n",
    "            country_name = subset.NAME_0.unique()[0]\n",
    "            country_capital = capitals[capitals[\"adm0name\"]==country_name].geometry\n",
    "            # if not available use centroid\n",
    "            if len(country_capital) == 0:\n",
    "                country_capital = gadm0[gadm0.NAME_0 == country].geometry.iloc[0].centroid\n",
    "            aoi = str(float(country_capital.y))+\",\"+str(float(country_capital.x))\n",
    "            # different road types\n",
    "            for road in road_types:\n",
    "                subset_road = get_road_subset(subset, road, combine_primary_and_trunk)\n",
    "                if len(subset_road) > 0:\n",
    "                    i += 1\n",
    "                    description = get_description(road)\n",
    "                    indicator_code = get_indicator_code(road)\n",
    "                    indicators.at[i,\"Indicator code\"] = \"'\"+indicator_code+\"'\"\n",
    "                    indicators = populate_indicator(indicators, i, subset_road, description, year, fully_covered_month, region, aoi, sub_aoi)\n",
    "print(\"Regions\")\n",
    "name1 = \"NAME_1_right\"\n",
    "for year in years:\n",
    "    print(year)\n",
    "    fname_gadm = get_fname_gadm(get_fname(year, merged), ext)\n",
    "    points = gpd.read_file(os.path.join(dirs[merged], fname_gadm)) # read points with gadm information\n",
    "    for region in gadm1_unique:\n",
    "        gadm1_region = gadm1[gadm1.NAME_1 == region]\n",
    "        if gadm1_region.NAME_0.iloc[0] in create_level1_indicators:      \n",
    "            # calc indicator stats for regions\n",
    "            subset = points[points[name1]==region]\n",
    "            if len(subset) > 0:\n",
    "                region = subset[name1].unique()[0]\n",
    "                sub_aoi = gadm1_region.geometry\n",
    "                center = sub_aoi.centroid # use the center of the region as aoi\n",
    "                aoi = str(float(center.y))+\",\"+str(float(center.x))\n",
    "                # different road types\n",
    "                for road in road_types:\n",
    "                    subset_road = get_road_subset(subset, road, combine_primary_and_trunk)\n",
    "                    if len(subset_road) > 0:\n",
    "                        i += 1\n",
    "                        description = get_description(road)\n",
    "                        indicator_code = get_indicator_code(road)\n",
    "                        indicators.at[i,\"Indicator code\"] = indicator_code\n",
    "                        indicators = populate_indicator(indicators, i, subset_road, description, year, fully_covered_month, region, aoi, sub_aoi.iloc[0].wkt)\n",
    "print(\"Done with indicator populating\")\n",
    "indicators_copy = indicators.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating indicator values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:72: RuntimeWarning: Mean of empty slice.\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [AOI, Country, Region, City, Site Name, Description, Method, EO Sensor, Input Data, Indicator code, Time, Measurement Value, Reference Description, Reference time, Reference value, Rule, Indicator Value, Sub-AOI, Y axis, Indicator Name, Color code, Data Provider, AOI_ID, Update frequency]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns]\n",
      "Done.. Writing\n",
      "Motorway\n",
      "Primary\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# \"Reference value\"\n",
    "# \"Color code\"\n",
    "# \"Indicator Value\"\n",
    "indicators_copy.to_csv(\"tmp_indicators.csv\", sep=\",\", index=False)\n",
    "indicators = indicators_copy.copy()\n",
    "print(\"Calculating indicator values\")\n",
    "for road in road_types:\n",
    "    for country in indicators.Country.unique():\n",
    "        country = \"EE\" if country == \"Estonia\" else country\n",
    "        indicator_country = indicators[indicators.Country==country]\n",
    "        indicator_country = indicator_country[indicator_country.Region == \"'None'\"]\n",
    "        if len(indicator_country) > 0:\n",
    "            indicator_road = indicator_country[indicator_country.Description==\"'\"+get_description(road)+\"'\"]\n",
    "            if len(indicator_road) > 0:\n",
    "                indicators = calc_indicators(indicators, indicator_road, deviation_threshold, color_codes)\n",
    "    for region in gadm1_unique:\n",
    "        gadm1_region = gadm1[gadm1.NAME_1 == region]\n",
    "        if gadm1_region.NAME_0.iloc[0] in create_level1_indicators:        \n",
    "            indicator_region = indicators[indicators.Region==\"'\"+region+\" Region'\"]\n",
    "            if len(indicator_region) > 0:\n",
    "                indicator_road = indicator_region[indicator_region.Description==\"'\"+get_description(road)+\"'\"]\n",
    "                if len(indicator_road) > 0:\n",
    "                    indicators = calc_indicators(indicators, indicator_road, deviation_threshold, color_codes)\n",
    "indicators_complete = indicators[indicators[\"Indicator Value\"].notna()]\n",
    "print(indicators_complete[indicators_complete[\"Indicator Value\"].isna()])\n",
    "print(\"Done.. Writing\")\n",
    "code_motorway = get_indicator_code(\"motorway\")\n",
    "code_primary = get_indicator_code(\"primary\")\n",
    "fpath_motorway = os.path.join(dirs[\"indicators\"], indicator_fname.replace(\"indicatorCode\", code_motorway))\n",
    "fpath_primary = os.path.join(dirs[\"indicators\"], indicator_fname.replace(\"indicatorCode\", code_primary))\n",
    "code = \"Indicator code\"\n",
    "print(\"Motorway\")\n",
    "indicators_motorway = indicators_complete[indicators_complete[code]==\"'\"+code_motorway+\"'\"]\n",
    "indicators_motorway = indicators_motorway.sort_values(\"Country\")\n",
    "indicators_motorway.to_csv(fpath_motorway, sep=\",\", index=False)\n",
    "print(\"Primary\")\n",
    "indicators_primary = indicators_complete[indicators_complete[code]==\"'\"+code_primary+\"'\"]\n",
    "indicators_primary = indicators_primary.sort_values(\"Country\")\n",
    "indicators_primary.to_csv(fpath_primary, sep=\",\", index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud-Optimized Geotiffs (COGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_truck_density(points_country, gadm0, spacing):\n",
    "    # create a grid and extract the counts in each pixel (represents a box of spacing dimensions)\n",
    "    country_geom = gadm0[gadm0.NAME_0==country].geometry\n",
    "    country_extent = country_geom.bounds\n",
    "    resolution = kilometers2degrees(spacing)\n",
    "    lon_len = country_extent.maxx-country_extent.minx\n",
    "    lat_len = country_extent.maxy-country_extent.miny\n",
    "    shape = (int(lat_len / resolution), int(lon_len / resolution))\n",
    "    arr = np.zeros(shape)\n",
    "    half_res = resolution / 2\n",
    "    first_lon = float(country_extent.minx + half_res)\n",
    "    first_lat = float(country_extent.maxy - half_res)\n",
    "    # working with pixel center\n",
    "    lon = np.arange(start=first_lon, stop=float(country_extent.maxx - half_res), step=resolution)\n",
    "    lat = np.flip(np.arange(start=float(country_extent.miny + half_res), stop=first_lat, step=resolution))\n",
    "    # get or each pixel (box) the number of trucks\n",
    "    for y in range(arr.shape[0]):\n",
    "        for x in range(arr.shape[1]):\n",
    "            lon_val = lon[x]\n",
    "            lat_val = lat[y]\n",
    "            pixel_box = box(lon_val-half_res, lat_val-half_res, lon_val+half_res, lat_val+half_res)\n",
    "            pixel_box_gpd = gpd.GeoDataFrame({\"geometry\":[pixel_box], \"index\":1})\n",
    "            \n",
    "            # set to nan if outside country borders (e.g. ocean)\n",
    "            country_polygon = country_geom.iloc[0]\n",
    "            if not pixel_box_gpd.geometry.iloc[0].intersects(country_polygon):\n",
    "                arr[y,x]= np.nan\n",
    "                continue\n",
    "            \n",
    "            # join with country points\n",
    "            points_country.crs = crs\n",
    "            pixel_box_gpd.crs = crs\n",
    "            points_pixel_box = gpd.sjoin(points_country, pixel_box_gpd, how=\"left\", op=\"within\")\n",
    "            points_pixel_box = points_pixel_box[points_pixel_box.index_right==0.]\n",
    "            if len(points_pixel_box) == 0:\n",
    "                arr[y,x] = 0.\n",
    "            else:\n",
    "                count = np.array(points_pixel_box[\"mean_trucks\"]).sum()\n",
    "                arr[y,x] = count\n",
    "    transform = Affine(resolution, 0, first_lon-half_res, 0, -resolution, first_lat+half_res)\n",
    "    return arr.astype(np.float32), transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gadm = gpd.read_file(os.path.join(dirs[\"processing\"], \"processing_grid_gadm.geojson\"))\n",
    "spacing = 10 #km\n",
    "if \"Trunk\" in road_types and \"Primary\" in road_types and combine_primary_and_trunk:\n",
    "    road_types.remove(\"Trunk\")\n",
    "for road_type in road_types:\n",
    "    indicator_code = get_indicator_code(road_type)\n",
    "    print(\"----- Road type: %s\" %(road_type))\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        points = gpd.read_file(os.path.join(dirs[merged], get_fname_gadm(get_fname(year, merged), \".gpkg\")))\n",
    "        points_road = points[points.osm_name==road_type]\n",
    "        if road_type == \"Primary\" and combine_primary_and_trunk:\n",
    "            points_trunk = points[points.osm_name==\"Trunk\"]\n",
    "            points_road = pd.concat([points_road, points_trunk])\n",
    "        for country in points.NAME_0.unique():\n",
    "            print(country)\n",
    "            points_country = points_road[points_road.NAME_0_right==country]\n",
    "            file_str = indicator_code+\"_\"+country+\"_\"+str(year)+\"_\"+road_type+\"_\"\n",
    "            fpath = os.path.join(dirs[\"COG\"], file_str+\".tiff\")\n",
    "            if os.path.exists(fpath):\n",
    "                print(\"Already exists %s %s %s\" %(country, str(year), road_type))\n",
    "            else:\n",
    "                if len(points_country) > 0:\n",
    "                    try:\n",
    "                        s1=datetime.datetime.now()\n",
    "                        point_density, transform = create_truck_density(points_country, gadm0, spacing)\n",
    "                        s2=datetime.datetime.now()-s1\n",
    "                        print(s2)\n",
    "                        print(\"Writing raster with shape: %s / %s\" %(str(point_density.shape[0]), str(point_density.shape[1])))\n",
    "                        meta = {\"driver\":\"GTiff\", \n",
    "                                \"height\":point_density.shape[0], \"width\":point_density.shape[1], \n",
    "                                \"transform\":transform, \"nodata\":\"nan\", \"count\":1, \"dtype\":point_density.dtype}\n",
    "                        with rasterio.open(fpath, \"w\", **meta) as target:\n",
    "                            target.write(np.array([point_density]))\n",
    "                        print(\"Done\")\n",
    "                    except:\n",
    "                        print(\"Creating point density raster failed %s %s %s\" %(country, road_type, str(year)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
